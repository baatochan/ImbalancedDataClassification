### Basic schema of the project

Plan na projekt:
* Wczytanie 20 zbiorów w formacie KEELa.
* Podzielenie kazdego zbioru w ramach 5krotnej 2foldowej stratyfikowej walidacji krzyzowej. Stratyfikowana, poniewaz zbior jest niezbalansowany. Wedlug wielu zrodel 5x2 foldowa crossvalid jest uwazana za uniwersalnei najlepsza do testowania, czyli jesli nie wiadomo nic o datasecie to ten da najlepsze wyniki). Kazdy algorytm jest testowany tak samo podzielonymi zbiorami danych, by mozna bylo jest porownac
* Po podzieleniu na podzbior uczacy i testowy, podzbior uczacy jest balansawany za pomoca algorytmu SMOTE (Synthetic Minority Oversampling Technique), ktory wykonuje oversampling obiektow klasy ktora jest w mniejszosci, jednak zamiast po prostu powtarzac istniejace obiekty w zbiorze uczacym, wykorzystaje algorytm knn do stworzenia syntetycznych przypadkow klasy w mniejszosci tworzac "podobne" obiekty. Zbiór testowy nie bedzie oversamplowany.
* Zoversamplowane dane uczace sa wykorzystywane do treningu 3 klasyfikatorow zlozonych:
	* AdaBoostClassifier - Klasyfikator, ktory tworzy n klasyfikatorow bazowych, gdzie pierwszy jest uczony "normalnie", natomiast nastepne sa uczone zmodyfikowanym datastetem za pomoca wag odpowiadajacym trudnosci rozpoznania danego obiektu przez poprzedni klasyfikator bazowy. W naszym projekcie tworzymy 50 instancji DecisionTreeClassifier (domyslny bazowy klasyfikator w implementacji ada boost w sklearn)
	* BaggingClassifier - Klasyfikator, ktory tworzy n klasyfikatorow bazowych, gdzie kazdy z nich jest uczony na bazie losowo wybranego zbioru (ze zwracaniem, wiec moga byc duplikaty), wiec kazdy z nich dostaje lekko inny zbior do nauki. W naszym projekcie tworzymy 50 instancji DecisionTreeClassifier (domyslny bazowy klasyfikator w implementacji baggingu w sklearn)
	* RandomForestClassifier - Klasyfikator, ktory tworzy n klasyfikatorow bazowych, gdzie pierwszy jest uczony "normalnie", natomiast nastepne sa uczone zmodyfikowanym datastetem wagami odpowiadajacymi trudnosci rozpoznania danego obiektu przez poprzedni klasyfikator bazowy. Dodatkowo kazdy z tych klasyfikatorow jest uczony zmodyfikowanym zbiorem cech (wiec nie kazdy uzywa wsyztskich cech). W naszym projekcie tworzymy 50 instancji DecisionTreeClassifier (domyslny bazowy klasyfikator w implementacji randomforest w sklearn)
* Do oceny jakosci uzywamy metryki o nazwie F1, ktora jest srednia harmoniczna dwoch parametrow - precyzji (czyli jak dobrze dana klasa jest poprawnie klasyfikowana posrod wysztkich obiektow tej klasy w zbiorze testowym) oraz recall (czyli jak dobrze dana klasa jest poprawnie klasyfikowana posrod wsyztskich obiektow sklasyfikowanych jako ta klasa)
* Po wykonaniu 5x2 crossvalid dodatkowo printujemy srednia arytmetyczna z 10 wartosci f1
* TODO: POTRZEBA ZDECYDOWAC JAKA METODE ANALIZY STATYSTYCZNEJ ROBIMY
